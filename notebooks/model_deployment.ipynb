{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713858836383
        }
      },
      "outputs": [],
      "source": [
        "# Ensure you have the dependencies for this notebook\n",
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Please fill following cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713858836566
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "NICKNAME = \"\"  # <-Please provide your nickname (lowercase no special characters)\n",
        "\n",
        "\n",
        "EXPERIMENT_NAME = f\"{NICKNAME}-HeartConditionClassifier-experiment\"\n",
        "ENDPOINT_NAME = f\"{NICKNAME}-api-endpoint\"\n",
        "\n",
        "MODELS = {\n",
        "    \"xgboost\": {\n",
        "        \"name\": f\"{NICKNAME}-HeartConditionClassifier-model-XGBoost\",\n",
        "        \"type\": \"XGBoost\",\n",
        "    },\n",
        "    \"lr\": {\n",
        "        \"name\": f\"{NICKNAME}-HeartConditionClassifier-model-LogisticRegression\",\n",
        "        \"type\": \"LogisticRegression\",\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 1. Load data (heart dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713860421907
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Load data (heart dataset)\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/HooverCz/ML-API/dev/heart.csv\")\n",
        "\n",
        "print(f\"Shape of DF: {df.shape}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 2. Train simple ML model\n",
        "\n",
        "### Step 1: Importing Libraries\n",
        "\n",
        "We start by importing necessary libraries for data preprocessing, model selection, and evaluation. These include numpy for numerical operations, scikit-learn for machine learning tasks, and XGBoost for gradient boosting.\n",
        "\n",
        "### Step 2: Data Splitting\n",
        "\n",
        "Next, we split our dataset into training and testing sets using the `train_test_split()` function from scikit-learn. This step is crucial to evaluate the model's performance on unseen data.\n",
        "\n",
        "### Step 3: Preprocessing\n",
        "\n",
        "We define transformers for categorical and continuous columns and combine them using `ColumnTransformer`. \n",
        "\n",
        "- **Categorical Preprocessing:** Categorical columns are one-hot encoded using the `OneHotEncoder` transformer to convert them into a numerical format. One-hot encoding is essential for algorithms that require numerical inputs, as it creates binary columns for each category.\n",
        "\n",
        "- **Continuous Preprocessing:** Continuous columns are scaled using `RobustScaler`. Robust scaling is robust to outliers and ensures that all features have the same scale, preventing certain features from dominating the model training process.\n",
        "\n",
        "### Step 4: Pipeline Construction\n",
        "\n",
        "We construct pipelines for logistic regression and XGBoost classifiers, combining preprocessing with the respective classifiers. Pipelines allow us to chain together multiple processing steps into a single object, making it easier to manage and reproduce.\n",
        "\n",
        "### Step 5: Hyperparameter Tuning\n",
        "\n",
        "We define a hyperparameter grid for grid search to find the best hyperparameters for logistic regression. Grid search is a technique used to find the optimal combination of hyperparameters for a given model, improving its performance.\n",
        "\n",
        "This pipeline setup enables efficient model training and hyperparameter tuning for classification tasks.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713860427386
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Split data and train/test the pipeline\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop(['output'], axis=1),\n",
        "    df['output'],\n",
        "    test_size=0.2,\n",
        "    random_state=42)\n",
        "\n",
        "\n",
        "# Define the columns to be encoded and scaled\n",
        "cat_cols = ['sex', 'exng', 'caa', 'cp', 'fbs', 'restecg', 'slp', 'thall']\n",
        "con_cols = [\"age\", \"trtbps\", \"chol\", \"thalachh\", \"oldpeak\"]\n",
        "\n",
        "# Define the preprocessor for categorical and continuous columns\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "continuous_transformer = Pipeline(steps=[\n",
        "    ('scaler', RobustScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', categorical_transformer, cat_cols),\n",
        "        ('con', continuous_transformer, con_cols)\n",
        "    ])\n",
        "\n",
        "# Combine preprocessing with the classifier in a single pipeline\n",
        "lr_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('clf', LogisticRegression())])\n",
        "\n",
        "xgboost_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('model', XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"))])\n",
        "\n",
        "\n",
        "# Define hyperparameter grid for grid search\n",
        "param_grid = {\n",
        "    'clf__penalty' : ['l1', 'l2'],\n",
        "    'clf__C' : np.logspace(-4, 4, 20),\n",
        "    'clf__solver' : ['liblinear']\n",
        "    }\n",
        "\n",
        "lr_grid_search = GridSearchCV(lr_pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 2.1. Train logistic regression model\n",
        "\n",
        "### Step 1: Fit Grid Search to Data\n",
        "\n",
        "The grid search is fitted to the training data using MLflow to track experiments. This allows us to efficiently search for the best hyperparameters for the logistic regression model.\n",
        "\n",
        "### Step 2: Get the Best Model\n",
        "\n",
        "The best model from the grid search is obtained using the `best_estimator_` attribute.\n",
        "\n",
        "### Step 3: Prediction\n",
        "\n",
        "Using the best model, predictions are made on the test data (`X_test`). Both class predictions (`y_pred`) and predicted probabilities (`y_pred_proba`) are calculated.\n",
        "\n",
        "### Step 4: Calculate Test Metrics\n",
        "\n",
        "Several test metrics such as accuracy, precision, recall, and F1-score are calculated using scikit-learn metrics functions. These metrics help evaluate the performance of the model on the test set.\n",
        "\n",
        "### Step 5: Generate ROC Curve\n",
        "\n",
        "An ROC curve is generated to visualize the trade-off between true positive rate (sensitivity) and false positive rate (1-specificity) of the model. This curve helps assess the model's predictive performance across different probability thresholds.\n",
        "\n",
        "### Step 6: Log Parameters and Metrics to MLflow\n",
        "\n",
        "The best hyperparameters and test metrics are logged to MLflow. Additionally, the ROC curve plot is saved as an artifact and logged to MLflow for later reference.\n",
        "\n",
        "### Step 7: Register the Final Model\n",
        "\n",
        "The final model is registered with MLflow, including its hyperparameters, evaluation metrics, and an input example. This allows for easy model reproducibility and deployment in future.\n",
        "\n",
        "### Step 8: Print Test Accuracy Score\n",
        "\n",
        "Finally, the test accuracy score of the logistic regression model is printed for easy reference.\n",
        "\n",
        "This comprehensive process enables efficient model training, evaluation, and tracking using MLflow for seamless experimentation and reproducibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713833083325
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Fit the grid search to the data\n",
        "mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)\n",
        "with mlflow.start_run(run_name=MODELS[\"lr\"][\"type\"]):\n",
        "    lr_grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best model from the grid search\n",
        "    best_model = lr_grid_search.best_estimator_\n",
        "\n",
        "    # Predict using the best model\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    y_pred_proba = best_model.predict_proba(X_test)\n",
        "\n",
        "    # Calculate test metrics\n",
        "    metrics = {\n",
        "        \"test_accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"test_precision\": precision_score(y_true=y_test, y_pred=y_pred),\n",
        "        \"test_recall\": recall_score(y_true=y_test, y_pred=y_pred),\n",
        "        \"test_f1\": f1_score(y_true=y_test, y_pred=y_pred),\n",
        "    }\n",
        "    tags = {\n",
        "        \"owner\": NICKNAME,\n",
        "        \"project\": \"heart-condition-classification\",\n",
        "        \"business_unit\": \"18AAD\",\n",
        "        \"model_type\": MODELS[\"lr\"][\"type\"],\n",
        "    }\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:,1])\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        "    # Plot the diagonal 50% line\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    # Plot the FPR and TPR achieved by our model\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.savefig(\"ROC-Curve.png\")\n",
        "\n",
        "    # Log parameters and metrics to MLflow\n",
        "    mlflow.log_params(lr_grid_search.best_params_)\n",
        "    mlflow.log_metrics(metrics)\n",
        "    mlflow.log_artifact(\"ROC-Curve.png\")\n",
        "    mlflow.set_tags(tags)\n",
        "\n",
        "    signature = mlflow.models.infer_signature(X_train, best_model.predict(X_train))\n",
        "\n",
        "    # Register the final model with MLflow\n",
        "    mlflow.sklearn.log_model(\n",
        "        best_model,\n",
        "        artifact_path=MODELS[\"lr\"][\"name\"],\n",
        "        input_example=X_train.iloc[:1],\n",
        "        signature=signature,\n",
        "        )\n",
        "    mlflow.register_model(\n",
        "        model_uri=f\"runs:/{mlflow.active_run().info.run_id}/{MODELS['lr']['name']}\",\n",
        "        name=MODELS[\"lr\"][\"name\"],\n",
        "        tags={**tags, **metrics},\n",
        "    )\n",
        "\n",
        "    print(f\"The test accuracy score of {MODELS['lr']['name']} is {metrics['test_accuracy']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 2.2. Train XGBoost classfier model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713833373711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Fit the grid search to the data\n",
        "mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)\n",
        "with mlflow.start_run(run_name=MODELS[\"xgboost\"][\"type\"]):\n",
        "    xgboost_pipeline.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    # Predict using the XGBoost model\n",
        "    y_pred = xgboost_pipeline.predict(X_test)\n",
        "    y_pred_proba = xgboost_pipeline.predict_proba(X_test)\n",
        "\n",
        "    # Calculate test metrics\n",
        "    metrics = {\n",
        "        \"test_accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"test_precision\": precision_score(y_true=y_test, y_pred=y_pred),\n",
        "        \"test_recall\": recall_score(y_true=y_test, y_pred=y_pred),\n",
        "        \"test_f1\": f1_score(y_true=y_test, y_pred=y_pred),\n",
        "    }\n",
        "    print(metrics)\n",
        "    tags = {\n",
        "        \"owner\": NICKNAME,\n",
        "        \"project\": \"heart-condition-classification\",\n",
        "        \"business_unit\": \"18AAD\",\n",
        "        \"model_type\": MODELS[\"xgboost\"][\"type\"],\n",
        "    }\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:,1])\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        "    # Plot the diagonal 50% line\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    # Plot the FPR and TPR achieved by our model\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.savefig(\"ROC-Curve.png\")\n",
        "\n",
        "    # Log parameters and metrics to MLflow\n",
        "    mlflow.log_params(xgboost_pipeline.get_params()[\"model\"].get_xgb_params())\n",
        "    mlflow.log_metrics(metrics)\n",
        "    mlflow.log_artifact(\"ROC-Curve.png\")\n",
        "    mlflow.set_tags(tags)\n",
        "\n",
        "    signature = mlflow.models.infer_signature(X_train, xgboost_pipeline.predict(X_train))\n",
        "\n",
        "    # Register the final model with MLflow\n",
        "    mlflow.sklearn.log_model(\n",
        "        xgboost_pipeline,\n",
        "        artifact_path=MODELS[\"xgboost\"][\"name\"],\n",
        "        input_example=X_train.iloc[:1],\n",
        "        signature=signature,\n",
        "        )\n",
        "    mlflow.register_model(\n",
        "        model_uri=f\"runs:/{mlflow.active_run().info.run_id}/{MODELS['xgboost']['name']}\",\n",
        "        name=MODELS[\"xgboost\"][\"name\"],\n",
        "        tags={**tags, **metrics},\n",
        "    )\n",
        "\n",
        "    print(f\"The test accuracy score of {MODELS['xgboost']['type']} is {metrics['test_accuracy']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 2.3. MLFlow autolog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713833842698
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Fit the grid search to the data\n",
        "mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)\n",
        "with mlflow.start_run(run_name=f'{MODELS[\"lr\"][\"type\"]}-autolog'):\n",
        "    mlflow.sklearn.autolog()\n",
        "    lr_grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best model from the grid search\n",
        "    best_model = lr_grid_search.best_estimator_\n",
        "\n",
        "    # Predict using the best model\n",
        "    y_pred = best_model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713833914783
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from mlflow.tracking.client import MlflowClient\n",
        "\n",
        "mlflow_client = MlflowClient()\n",
        "model_name = MODELS['lr']['name']\n",
        "\n",
        "for item in mlflow_client.search_model_versions(f\"name = '{model_name}'\"):\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713833942062
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "mlflow_client.search_runs(experiment_ids=mlflow.get_experiment_by_name(f\"{EXPERIMENT_NAME}\").experiment_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 3. Batch Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713833986026
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "model_version = mlflow_client.search_model_versions(f\"name = '{model_name}'\")[0].version\n",
        "print(f\"Newest version for model: {model_name} is version: {model_version}\")\n",
        "\n",
        "model = mlflow.sklearn.load_model(model_uri=f\"models:/{model_name}/{model_version}\")\n",
        "type(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713833996830
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 4. Real-time (online) inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 4.1. Create API inference endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713860379394
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "import json\n",
        "import requests\n",
        "import mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713858852003
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Get MLclient for interacting with azureml workspace via code\n",
        "\n",
        "ml_client = MLClient.from_config(credential=DefaultAzureCredential())\n",
        "ml_client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713860388234
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from mlflow.deployments import get_deploy_client\n",
        "\n",
        "deployment_client = get_deploy_client(mlflow.get_tracking_uri())\n",
        "deployment_client.__dict__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "endpoint_config = {\n",
        "    \"auth_mode\": \"key\",\n",
        "    \"identity\": {\n",
        "        \"type\": \"system_assigned\"\n",
        "    }\n",
        "}\n",
        "endpoint_config_path = \"endpoint_config.json\"\n",
        "with open(endpoint_config_path, \"w\") as outfile:\n",
        "    outfile.write(json.dumps(endpoint_config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713834351520
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Create empty endpoint\n",
        "endpoint = deployment_client.create_endpoint(\n",
        "    name=ENDPOINT_NAME,\n",
        "    config={\"endpoint-config-file\": endpoint_config_path},)\n",
        "\n",
        "endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713834511136
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Create deployment config - compute type + size and dump it as json\n",
        "deployment_name = \"default\"\n",
        "deploy_config = {\n",
        "    \"instance_type\": \"Standard_DS2_v2\",\n",
        "    \"instance_count\": 1,\n",
        "}\n",
        "\n",
        "deployment_config_path = \"deployment_config.json\"\n",
        "with open(deployment_config_path, \"w\") as outfile:\n",
        "    outfile.write(json.dumps(deploy_config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713835228849
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Deploy our ML model to the endpoint (takes between 6-10 minutes)\n",
        "\n",
        "deployment = deployment_client.create_deployment(\n",
        "    name=deployment_name,\n",
        "    endpoint=ENDPOINT_NAME,\n",
        "    model_uri=f\"models:/{model_name}/{model_version}\",\n",
        "    config={\"deploy-config-file\": deployment_config_path},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713835266784
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Update endpoint to point 100 % of traffic to our model deployment\n",
        "\n",
        "traffic_config = {\"traffic\": {deployment_name: 100}}\n",
        "traffic_config_path = \"traffic_config.json\"\n",
        "with open(traffic_config_path, \"w\") as outfile:\n",
        "    outfile.write(json.dumps(traffic_config))\n",
        "\n",
        "\n",
        "deployment_client.update_endpoint(\n",
        "    endpoint=ENDPOINT_NAME,\n",
        "    config={\"endpoint-config-file\": traffic_config_path},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713860532290
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "\n",
        "# Get URL and credentials to the endpoint\n",
        "\n",
        "scoring_uri = deployment_client.get_endpoint(endpoint=ENDPOINT_NAME)[\"properties\"][\"scoringUri\"]\n",
        "print(scoring_uri)\n",
        "\n",
        "endpoint_secret_key = \"\"  # <- please fill; navigate to Endpoints (left menu) -> Select your endpoint -> Consume\n",
        "\n",
        "# Make API call to the endpoint\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": (\"Bearer \" + endpoint_secret_key),\n",
        "    \"azureml-model-deployment\": \"default\",\n",
        "}\n",
        "\n",
        "sample_data = X_test.sample(5).to_json(orient=\"split\", index=False)\n",
        "\n",
        "sample_request = {\n",
        "    \"input_data\": json.loads(sample_data)\n",
        "}\n",
        "\n",
        "print(f\"Sample request: {sample_request}\")\n",
        "\n",
        "req = requests.post(scoring_uri, json=sample_request, headers=headers)\n",
        "\n",
        "\n",
        "print(f\"Response: {req.json()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
